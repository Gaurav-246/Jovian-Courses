{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Data :"
      ],
      "metadata": {
        "id": "PsrZ3P7Q_A_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " ! pip install -q kaggle"
      ],
      "metadata": {
        "id": "y5zfK4EK_AkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdHdIp1Ns5qd",
        "outputId": "58c75f67-67ad-4223-ac6c-f75685f62656"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/Cyclegan/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpT8MDRfwB5a",
        "outputId": "dfd79e56-8c87-40b2-8fec-27b585079494"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Cyclegan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/MyDrive/Cyclegan/\""
      ],
      "metadata": {
        "id": "_tsJXNI6zWNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download -d balraj98/horse2zebra-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaVipyGCzbFx",
        "outputId": "0208effb-da9f-46a1-cc48-68b4937115d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "401 - Unauthorized\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Builiding the model :"
      ],
      "metadata": {
        "id": "3ZzN9rLM-8Kw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iF-0yeBRPpuf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_default_device():\n",
        "    # Pick GPU if available, else CPU\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "    \n",
        "def to_device(data, device):\n",
        "    # Move tensor(s) to chosen device\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    # Wrap a dataloader to move data to a device\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        # Yield a batch of data after moving it to device\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        # Number of batches\n",
        "        return len(self.dl)"
      ],
      "metadata": {
        "id": "ukXlPl5qP95k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = get_default_device()\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46tOjINxQObc",
        "outputId": "742c622d-98b1-4b23-c78c-32d834fee266"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from tqdm.notebook import tqdm\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "EHwfyltEQkVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = nn.Sequential(\n",
        "    # in: 3 x 64 x 64\n",
        "\n",
        "    nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 64 x 32 x 32\n",
        "\n",
        "    nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.InstanceNorm2d(128),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 128 x 16 x 16\n",
        "\n",
        "    nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.InstanceNorm2d(256),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 256 x 8 x 8\n",
        "\n",
        "    nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.InstanceNorm2d(512),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 512 x 4 x 4\n",
        "\n",
        "    nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "    # out: 1 x 1 x 1\n",
        "\n",
        "    nn.Flatten(),\n",
        "    nn.Sigmoid())  \n",
        "        "
      ],
      "metadata": {
        "id": "zM9G1yKjDJ27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, f):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.conv = nn.Sequential(nn.Conv2d(f, f, 3, 1, 1), nn.InstanceNorm2d(f), nn.ReLU(),\n",
        "                                  nn.Conv2d(f, f, 3, 1, 1))\n",
        "        self.norm = nn.InstanceNorm2d(f)\n",
        "    def forward(self, x):\n",
        "        return nn.functional.relu(self.norm(self.conv(x)+x))"
      ],
      "metadata": {
        "id": "0dZIddRiAbJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = 64"
      ],
      "metadata": {
        "id": "oM0eP7kDNvNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_layers = [nn.ReflectionPad2d(3),\n",
        "                  # 3 x 70 x 70                                           \n",
        "                  nn.Conv2d( 3, f, kernel_size=7, stride=1, padding=0), nn.InstanceNorm2d(f), nn.ReLU(True),\n",
        "                  # 64 x 64 x 64\n",
        "                  nn.Conv2d( f, 2*f, kernel_size=3, stride=2, padding=1), nn.InstanceNorm2d(2*f), nn.ReLU(True),\n",
        "                  # 128 x 32 x 32\n",
        "                  nn.Conv2d(2*f, 4*f, kernel_size=3, stride=2, padding=1), nn.InstanceNorm2d(4*f), nn.ReLU(True)\n",
        "                  # 256 x 16 x 16\n",
        "                  ]\n",
        "for i in range(int(6)):\n",
        "    gen_layers.append(ResBlock(4*f))  # 256 x 16 x 16\n",
        "\n",
        "gen_layers.extend([\n",
        "                nn.ConvTranspose2d(4*f, 4*2*f, kernel_size=3, stride=1, padding=1), nn.PixelShuffle(2), nn.InstanceNorm2d(2*f), nn.ReLU(True),\n",
        "                # 128 x 32 x 32\n",
        "                nn.ConvTranspose2d(2*f, 4*f, kernel_size=3, stride=1, padding=1), nn.PixelShuffle(2), nn.InstanceNorm2d(  f), nn.ReLU(True),\n",
        "                # 64 x 64 x 64\n",
        "                nn.ReflectionPad2d(3), nn.Conv2d(f, 3, kernel_size = 7, stride=1, padding=0),\n",
        "                # 3 x 64 x 64\n",
        "                nn.Tanh()])\n",
        "\n",
        "generator = nn.Sequential(*gen_layers)"
      ],
      "metadata": {
        "id": "APA2W0uNDG_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_discriminator_A(real_A, opt_d_A):\n",
        "\n",
        "  # Clear discriminator gradients\n",
        "  opt_d_A.zero_grad()\n",
        "\n",
        "  # Training of Discriminator A\n",
        "\n",
        "  real_preds = discriminator(real_A)\n",
        "  real_targets = torch.ones(real_A.size(0), 1, device=device)\n",
        "  real_loss = F.binary_cross_entropy(real_preds, real_targets)\n",
        "\n",
        "  # Generate fake images\n",
        "  latent_vector = torch.randn(batch_size, latent_size, 1, 1, device=device)    # Figure out to input fake A with latent vector\n",
        "  fake = generator(latent_vector)\n",
        "\n",
        "  # Training with fake images\n",
        "  fake_preds = discriminator(fake)\n",
        "  fake_targets = torch.zeros(fake.size(0), 1, device=device)\n",
        "  fake_loss = F.binary_cross_entropy(fake_preds, fake_targets)\n",
        "\n",
        "  # Update discriminator weights\n",
        "  loss = real_loss + fake_loss\n",
        "  loss.backward()\n",
        "  opt_d_A.step()\n",
        "  return loss.item() "
      ],
      "metadata": {
        "id": "6JbpkyIrIinZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_discriminator_B(real_B, opt_d_B):\n",
        "\n",
        "  # Clear discriminator gradients\n",
        "  opt_d_B.zero_grad()\n",
        "\n",
        "  # Training of Discriminator A\n",
        "\n",
        "  real_preds = discriminator(real_B)\n",
        "  real_targets = torch.ones(real_B.size(0), 1, device=device)\n",
        "  real_loss = F.binary_cross_entropy(real_preds, real_targets)\n",
        "\n",
        "  # Generate fake images\n",
        "  latent_vector = torch.randn(batch_size, latent_size, 1, 1, device=device)    # Figure out to input fake B with latent vector\n",
        "  fake = generator(latent_vector)\n",
        "\n",
        "  # Training with fake images\n",
        "  fake_preds = discriminator(fake)\n",
        "  fake_targets = torch.zeros(fake.size(0), 1, device=device)\n",
        "  fake_loss = F.binary_cross_entropy(fake_preds, fake_targets)\n",
        "\n",
        "  # Update discriminator weights\n",
        "  loss = real_loss + fake_loss\n",
        "  loss.backward()\n",
        "  opt_d_B.step()\n",
        "  return loss.item() "
      ],
      "metadata": {
        "id": "L5hgfB1YQxuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_generator_A(opt_g_A):\n",
        "    # Clear generator gradients\n",
        "    opt_g_A.zero_grad()\n",
        "    \n",
        "    # Generate fake images\n",
        "    latent = torch.randn(batch_size, latent_size, 1, 1, device=device)        # Latent should be input with B\n",
        "    fake_images = generator(latent)\n",
        "    \n",
        "    # Try to fool the discriminator\n",
        "    preds = discriminator(fake_images)\n",
        "    targets = torch.ones(batch_size, 1, device=device)\n",
        "    loss = F.binary_cross_entropy(preds, targets)\n",
        "    \n",
        "    # Update generator weights\n",
        "    loss.backward()\n",
        "    opt_g_A.step()\n",
        "    \n",
        "    return loss.item()"
      ],
      "metadata": {
        "id": "6nTjVw5dQ9mD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_generator_B(opt_g_B):\n",
        "    # Clear generator gradients\n",
        "    opt_g_B.zero_grad()\n",
        "    \n",
        "    # Generate fake images\n",
        "    latent = torch.randn(batch_size, latent_size, 1, 1, device=device)        # Latent should be input with A\n",
        "    fake_images = generator(latent)\n",
        "    \n",
        "    # Try to fool the discriminator\n",
        "    preds = discriminator(fake_images)\n",
        "    targets = torch.ones(batch_size, 1, device=device)\n",
        "    loss = F.binary_cross_entropy(preds, targets)\n",
        "    \n",
        "    # Update generator weights\n",
        "    loss.backward()\n",
        "    opt_g_B.step()\n",
        "    \n",
        "    return loss.item()"
      ],
      "metadata": {
        "id": "_EsmjZ7BRV8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.utils import save_image"
      ],
      "metadata": {
        "id": "YabaEsoPp2ry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_dir = 'generated'\n",
        "os.makedirs(sample_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "bX2dvN-cp6QK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_samples(index, latent_input, show=True):\n",
        "    fake_images = generator(latent_input)\n",
        "    fake_fname = 'generated-images-{0:0=4d}.png'.format(index)\n",
        "    save_image(denorm(fake_images), os.path.join(sample_dir, fake_fname), nrow=8)\n",
        "    print('Saving', fake_fname)\n",
        "    if show:\n",
        "        fig, ax = plt.subplots(figsize=(1, 2))\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "        ax.imshow(make_grid(fake_images.cpu().detach(), nrow=1).permute(1, 2, 0))"
      ],
      "metadata": {
        "id": "t4V5TicgpRO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(epochs, lr, start_idx=1):\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    # Losses & scores\n",
        "    losses_g_A = []\n",
        "    losses_g_B = []\n",
        "    losses_d_A = []\n",
        "    losses_d_B = []\n",
        "    \n",
        "    # Create optimizers\n",
        "    opt_d_A = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "    opt_d_B = opt_d_A\n",
        "    opt_g_A = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "    opt_g_B = opt_g_A\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for real_images_A, _ in tqdm(train_dl_A):\n",
        "            # Train discriminator A\n",
        "            loss_d_A = train_discriminator_A(real_images_A, opt_d_A)\n",
        "            # Train generator A\n",
        "            loss_g_A = train_generator_A(opt_g_A)\n",
        "        for real_images_B, _ in tqdm(train_dl_B):  \n",
        "            # Train discriminator B\n",
        "            loss_d_B = train_discriminator_B(real_images_B, opt_d_B)\n",
        "            # Train generator B\n",
        "            loss_g_B = train_generator_B(opt_g_B)\n",
        "\n",
        "        # Record losses & scores\n",
        "        losses_g_A.append(loss_g_A)\n",
        "        losses_d_A.append(loss_d_A)\n",
        "        losses_g_B.append(loss_g_B)\n",
        "        losses_d_B.append(loss_d_B)\n",
        "        \n",
        "        # Log losses & scores (last batch)\n",
        "        print(\"Epoch [{}/{}], loss_g_A: {:.4f}, loss_d_A: {:.4f}, loss_g_B: {:.4f}, loss_d_B: {:.4f}\".format(\n",
        "            epoch+1, epochs, loss_g_A, loss_d_A, loss_g_B, loss_d_B))\n",
        "    \n",
        "        # Save generated images\n",
        "        save_samples(epoch+start_idx, fixed_latent, show=False)\n",
        "    \n",
        "    return losses_g, losses_d, real_scores, fake_scores"
      ],
      "metadata": {
        "id": "TIz6Yi5cXser"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}